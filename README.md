# Medusa-CleanupTools

A suite of Python tools for cleaning up legacy digital collections. It's also my final class project for IS 452. These are simple scripts for performing well-defined tasks as part of my regular duties, so they are designed to be run in a Linux console (by cd'ing to their working location and then invoking them with "python3 scriptName.py"), sometimes with inputs from my Windows workstation (ie, they're designed to tolerate input addresses with backslashes). As of my final submission for that class, the project includes the following 5 finished scripts:

# TreeReporter
Recursively generates a tree diagram of the specified location, listing the total number and size of each file extension in each subdirectory, and displays it in the console. (Future goals: print to csv.)

## 0byteReporter.py
Recursively detects empty files (with filesize of 0 bytes), arranges them in a tree, then prints them to a uniquely-named file. Scan location is specified via user input (using forward slashes) while the program is running.

## 0byteRemover.py
Recursively detects empty files (with filesize of 0 bytes) from a location specified via user input, then moves them to another specified directory for inspection and/or deletion. Automatically renames identically-named files to prevent clobbering. Prints list of removed file paths to txt file in default working location.

## BulkStager.py
When restructuring files already deposited in the Medusa digital preservation repository, we typically want to securely copy them to a working area. This script is designed to accept a list of directory paths copied from a file management program running on a Windows machine (as addresses.txt -- sample file provided), process them into a more convenient (and identifiable) set of new locations, invoke the Bash shell to copy the files there using Rsync, run Diff on them to ensure no files were dropped due to a network interruption, print a report of this to file, and finally ring a console bell once finished.

## FileSorter.py
This one is a bit of a work in progress, though it works very well for the very specific use case I originally wrote it for: sorting photos of preservation items into the archival file structure we use (at this point in the workflow, already generated by a script someone else wrote long ago), something previous GA's did by drag-and-drop (hundreds of folders, with several photos each!). So there are file paths hard-coded in that I would eventually like to make more flexible, with some sort of autodetect, which would allow it to be used in more contexts. The user will be prompted for location data while the program is running.

